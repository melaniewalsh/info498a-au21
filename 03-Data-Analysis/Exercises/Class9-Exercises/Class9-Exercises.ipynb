{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 9 Exercises "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These exercises will help you practice the skills and concepts that you learned in today's class.\n",
    "\n",
    "To get participation credit for today's class, make sure that you work on these exercises and then submit a screenshot or PDF of your work to the appropriate assignment page in Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasheets for Datasets\n",
    "### Am I The Asshole? Reddit Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that we're working with in this lesson is taken from the subreddit [\"Am I The Asshole?\"](https://www.reddit.com/r/AmItheAsshole/) — only posts that had more than 2,000 upvotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Pandas library, we first need to `import` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Display Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Pandas will display 60 rows and 20 columns. I often change [Pandas' default display settings](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html) to show more rows or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data \"top-readdit-aita-posts.csv\" and save it as the variable `reddit_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv('top-reddit-aita-posts.csv', encoding='utf=8', delimiter=',',\n",
    "                        #parse_dates=['full_date'] \n",
    "                        # We will save this for later!\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate descriptive statistics for all columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>full_date</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_crossposts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2932</td>\n",
       "      <td>2932</td>\n",
       "      <td>2932</td>\n",
       "      <td>2932</td>\n",
       "      <td>2929</td>\n",
       "      <td>2932</td>\n",
       "      <td>2932</td>\n",
       "      <td>2932.000000</td>\n",
       "      <td>2932.000000</td>\n",
       "      <td>2932.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2859</td>\n",
       "      <td>2932</td>\n",
       "      <td>306</td>\n",
       "      <td>2932</td>\n",
       "      <td>2834</td>\n",
       "      <td>2932</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2020-07-24 19:13:49+00:00</td>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>AITA for kicking my cousin off of my sister’s wedding Zoom call?</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comments/hx80wd/aita_for_kicking_my_cousin_off_of_my_sisters/</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>2932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7818.791269</td>\n",
       "      <td>1350.299795</td>\n",
       "      <td>0.171896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7582.587863</td>\n",
       "      <td>1273.432164</td>\n",
       "      <td>0.700773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2775.000000</td>\n",
       "      <td>545.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4267.500000</td>\n",
       "      <td>927.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10704.250000</td>\n",
       "      <td>1674.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71339.000000</td>\n",
       "      <td>12543.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                  full_date        date  \\\n",
       "count        2932                       2932        2932   \n",
       "unique       2859                       2932         306   \n",
       "top     [deleted]  2020-07-24 19:13:49+00:00  2020-06-11   \n",
       "freq            9                          1          27   \n",
       "mean          NaN                        NaN         NaN   \n",
       "std           NaN                        NaN         NaN   \n",
       "min           NaN                        NaN         NaN   \n",
       "25%           NaN                        NaN         NaN   \n",
       "50%           NaN                        NaN         NaN   \n",
       "75%           NaN                        NaN         NaN   \n",
       "max           NaN                        NaN         NaN   \n",
       "\n",
       "                                                                   title  \\\n",
       "count                                                               2932   \n",
       "unique                                                              2932   \n",
       "top     AITA for kicking my cousin off of my sister’s wedding Zoom call?   \n",
       "freq                                                                   1   \n",
       "mean                                                                 NaN   \n",
       "std                                                                  NaN   \n",
       "min                                                                  NaN   \n",
       "25%                                                                  NaN   \n",
       "50%                                                                  NaN   \n",
       "75%                                                                  NaN   \n",
       "max                                                                  NaN   \n",
       "\n",
       "         selftext  \\\n",
       "count        2929   \n",
       "unique       2834   \n",
       "top     [removed]   \n",
       "freq           92   \n",
       "mean          NaN   \n",
       "std           NaN   \n",
       "min           NaN   \n",
       "25%           NaN   \n",
       "50%           NaN   \n",
       "75%           NaN   \n",
       "max           NaN   \n",
       "\n",
       "                                                                                                         url  \\\n",
       "count                                                                                                   2932   \n",
       "unique                                                                                                  2932   \n",
       "top     https://www.reddit.com/r/AmItheAsshole/comments/hx80wd/aita_for_kicking_my_cousin_off_of_my_sisters/   \n",
       "freq                                                                                                       1   \n",
       "mean                                                                                                     NaN   \n",
       "std                                                                                                      NaN   \n",
       "min                                                                                                      NaN   \n",
       "25%                                                                                                      NaN   \n",
       "50%                                                                                                      NaN   \n",
       "75%                                                                                                      NaN   \n",
       "max                                                                                                      NaN   \n",
       "\n",
       "            subreddit  upvote_score  num_comments  num_crossposts  \n",
       "count            2932   2932.000000   2932.000000     2932.000000  \n",
       "unique              1           NaN           NaN             NaN  \n",
       "top     AmItheAsshole           NaN           NaN             NaN  \n",
       "freq             2932           NaN           NaN             NaN  \n",
       "mean              NaN   7818.791269   1350.299795        0.171896  \n",
       "std               NaN   7582.587863   1273.432164        0.700773  \n",
       "min               NaN   2001.000000      1.000000        0.000000  \n",
       "25%               NaN   2775.000000    545.000000        0.000000  \n",
       "50%               NaN   4267.500000    927.000000        0.000000  \n",
       "75%               NaN  10704.250000   1674.750000        0.000000  \n",
       "max               NaN  71339.000000  12543.000000       13.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the minimum and maximum upvote score?\n",
    "- Who is the most frequent author?\n",
    "- How many rows are blank in the \"selftext\" column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the column \"selftext\" as simply \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the NaN values in the column \"text\" with the words \"No text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['text'] = reddit_df['text'].fillna('No text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter By String Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for words or phrases in the Reddit data. Can you find any patterns or trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_filter  = reddit_df['text'].str.contains('wedding', case=False, na=False)\n",
    "reddit_df[word_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df[word_filter].to_csv('Filtered-Reddit-Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['text'].apply(make_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_make_lower(df):\n",
    "    return df['text'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.apply(df_make_lower, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a Ratio Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting \"ratio'd\" in social media parlance usually means that you receive more comments than upvotes (or retweets, etc.). Let's make a function that will calculate a post's \"ratio.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ratio(df):\n",
    "    comments = df['num_comments']\n",
    "    upvotes = df['upvote_score']\n",
    "    \n",
    "    return comments / upvotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function above to the entire DataFrame below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['ratio'] = reddit_df...#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What might be another way to create this new column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['ratio2'] = reddit_df...#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the DataFrame from the highest ratio to the lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df...#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Pandas Data Convert Method** | **Explanation**                                                                                   |\n",
    "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
    "| `pd.to_datetime(df['column_name'], format='&Y-%M')`         | Convert column to datetime, specify date input format                                               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['full_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(reddit_df['full_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['full_date'] = pd.to_datetime(reddit_df['full_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.dt` (datetime) to extract specific parts of the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(reddit_df['full_date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['date'] = pd.to_datetime(reddit_df['full_date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(reddit_df['full_date']).dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['full_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['full_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['full_date'].dt.second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot By Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it's useful to add a dummy column called \"count\" with 1s for every row if we're interested in the frequency of values over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.groupby('full_date')['count'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.groupby('date')['count'].sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Pandas Datetime Index Methods** | **Explanation**                                                                                   |\n",
    "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
    "| `df.resample('M')`         | Resample, or essentially group by, different spans of time, e.g., `Y`, `M`, `D`, `17min`                                                |\n",
    "| `df.loc['2018':'2019']`         | Index by label and slice DataFrame between the years 2018 and 2019                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common approach to working with time series infromation is to make the datetime column into our Pandas index. There are some special things we can do with a datetime index, such as slice the data by dates more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the \"Date\" column our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = reddit_df.set_index('full_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, because we can use `.loc` to index by date label, we can get only values from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.loc['2018']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also slice between dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.sort_index().loc['2018-05':'2018-10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we can do with a Datetime Index is to `.resample()`, or essentailly group by, different time period spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.resample('M').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.resample('M').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.resample('M')['count'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.resample('D')['count'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.resample('Y')['count'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_filter = reddit_df['selftext'].str.contains('summer', na=False, case=False)\n",
    "\n",
    "# Plot all Reddit posts over time\n",
    "reddit_df.resample('D')['count'].sum().plot(kind='area')\n",
    "#Plot only posts that contain a givern word\n",
    "reddit_df[word_filter].resample('D')['count'].sum().plot(kind='area')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
