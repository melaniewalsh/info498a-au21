{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition ‚Äî¬†Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we're going to learn about a text analysis method called *Named Entity Recognition* (NER). This method will help us computationally identify people, places, and things (of various kinds) in a text or collection of texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install spaCy and Download Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to install spaCy and the English-language model (`en_core_web_sm`). This is the model that was trained on the annotated \"OntoNotes\" corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/melwalsh/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - spacy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    catalogue-1.0.0            |   py38h50d1736_3          13 KB  conda-forge\n",
      "    conda-4.10.3               |   py38h50d1736_3         3.1 MB  conda-forge\n",
      "    cymem-2.0.3                |   py38hc84c608_2          33 KB  conda-forge\n",
      "    cython-blis-0.4.1          |   py38h64e0658_1         3.1 MB  conda-forge\n",
      "    murmurhash-1.0.0           |   py38hc84c608_0          15 KB  conda-forge\n",
      "    plac-0.9.6                 |             py_1          18 KB  conda-forge\n",
      "    preshed-3.0.2              |   py38hc84c608_3          91 KB  conda-forge\n",
      "    python_abi-3.8             |           2_cp38           4 KB  conda-forge\n",
      "    spacy-2.3.2                |   py38h02bb52f_0         7.8 MB  conda-forge\n",
      "    srsly-1.0.2                |   py38hc84c608_0         196 KB  conda-forge\n",
      "    thinc-7.4.1                |   py38h9a3f56e_0         1.5 MB  conda-forge\n",
      "    wasabi-0.8.2               |     pyh44b312d_0          23 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        15.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  catalogue          conda-forge/osx-64::catalogue-1.0.0-py38h50d1736_3\n",
      "  cymem              conda-forge/osx-64::cymem-2.0.3-py38hc84c608_2\n",
      "  cython-blis        conda-forge/osx-64::cython-blis-0.4.1-py38h64e0658_1\n",
      "  murmurhash         conda-forge/osx-64::murmurhash-1.0.0-py38hc84c608_0\n",
      "  plac               conda-forge/noarch::plac-0.9.6-py_1\n",
      "  preshed            conda-forge/osx-64::preshed-3.0.2-py38hc84c608_3\n",
      "  python_abi         conda-forge/osx-64::python_abi-3.8-2_cp38\n",
      "  spacy              conda-forge/osx-64::spacy-2.3.2-py38h02bb52f_0\n",
      "  srsly              conda-forge/osx-64::srsly-1.0.2-py38hc84c608_0\n",
      "  thinc              conda-forge/osx-64::thinc-7.4.1-py38h9a3f56e_0\n",
      "  wasabi             conda-forge/noarch::wasabi-0.8.2-pyh44b312d_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda              pkgs/main::conda-4.10.3-py38hecd8cb5_0 --> conda-forge::conda-4.10.3-py38h50d1736_3\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy[apple]\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (3.2.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: setuptools in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/melwalsh/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy --upgrade\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: spaCy offers [models for other languages](https://spacy.io/usage/models#languages) including German, French, Spanish, Portuguese, Italian, Dutch, Greek, Norwegian, and Lithuanian. Languages such as Russian, Ukrainian, Thai, Chinese, Japanese, Korean and Vietnamese don't currently have their own NLP models. However, spaCy offers language and tokenization support for many of these language with external dependencies ‚Äî such as [PyviKonlpy](https://github.com/konlpy/konlpy) for Korean or [Jieba](https://github.com/fxsjy/jieba) for Chinese.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to import `spacy` and `displacy`, a special spaCy module for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to import the `Counter` module for counting people, places, and things, and the `pandas` library for organizing and displaying data (we're also changing the pandas default max row and column width display setting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the language model and save it as the variable `nlp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we open and read a text file. Then we run `nlp()` on the text to create our processed spaCy document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../Harry\"\n",
    "text = open(filepath, encoding='utf-8').read()\n",
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a Named Entities chart taken from [spaCy's website](https://spacy.io/api/annotation#named-entities), which shows the different named entities that spaCy can identify as well as their corresponding type labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Type Label|Description|\n",
    "|:---:|:---:|\n",
    "|PERSON|People, including fictional.|\n",
    "|NORP|Nationalities or religious or political groups.|\n",
    "|FAC|Buildings, airports, highways, bridges, etc.|\n",
    "|ORG|Companies, agencies, institutions, etc.|\n",
    "|GPE|Countries, cities, states.|\n",
    "|LOC|Non-GPE locations, mountain ranges, bodies of water.|\n",
    "|PRODUCT|Objects, vehicles, foods, etc. (Not services.)|\n",
    "|EVENT|Named hurricanes, battles, wars, sports events, etc.|\n",
    "|WORK_OF_ART|Titles of books, songs, etc.|\n",
    "|LAW|Named documents made into laws.|\n",
    "|LANGUAGE|Any named language.|\n",
    "|DATE|Absolute or relative dates or periods.|\n",
    "|TIME|Times smaller than a day.|\n",
    "|PERCENT|Percentage, including ‚Äù%‚Äú.|\n",
    "|MONEY|Monetary values, including unit.|\n",
    "|QUANTITY|Measurements, as of weight or distance.|\n",
    "|ORDINAL|‚Äúfirst‚Äù, ‚Äúsecond‚Äù, etc.|\n",
    "|CARDINAL|Numerals that do not fall under another type.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly see spaCy's NER in action, we can use the [spaCy module `displacy`](https://spacy.io/usage/visualizers#ent) with the `style=` parameter set to \"ent\"  (short for entities):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "displacy.render(document, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the named entities in our `document` can be found in the `document.ents` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "document.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the named entities in `document.ents` contains [more information about itself](https://spacy.io/usage/linguistic-features#accessing). To get the entity label, we can use the `.label_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "for named_entity in document.ents:\n",
    "    print(named_entity, named_entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract just the named entities that have been identified as `PERSON`, we can add a simple `if` statement into the mix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "for named_entity in document.ents:\n",
    "    if named_entity.label_ == \"PERSON\":\n",
    "        print(named_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER with The House on Mango Street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"../texts/literature/The-House-on-Mango-Street-Sandra-Cisneros.txt\").read()\n",
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get People"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Type Label|Description|\n",
    "|:---:|:---:|\n",
    "|PERSON|People, including fictional.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will extract named entitities from *The House on Mango Street*, count them up with `Counter()`, and then create a DataFrame of the results.\n",
    "\n",
    "Your job is to make sure that we only get named entities that are **people**. Insert the approriate Python code below.\n",
    "\n",
    "*Hint: Look at the examples above for guidance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = []\n",
    "\n",
    "for named_entity in document.ents:\n",
    "    # Your Code Here\n",
    "        #Your Code Here\n",
    "\n",
    "people_tally = Counter(people)\n",
    "\n",
    "df = pd.DataFrame(people_tally.most_common(), columns=['character', 'count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Type Label|Description|\n",
    "|:---:|:---:|\n",
    "|GPE|Countries, cities, states.|\n",
    "|LOC|Non-GPE locations, mountain ranges, bodies of water.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will extract named entitities from *The House on Mango Street*, count them up with `Counter()`, and then create a DataFrame of the results.\n",
    "\n",
    "Your job is to make sure that we only get named entities that are *either* **countries, cities, states** OR **non-GPE locations**. Insert the approriate Python code below.\n",
    "\n",
    "*Hint: Look at the examples above for guidance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = []\n",
    "\n",
    "for named_entity in document.ents:\n",
    "    # Your Code Here\n",
    "        # Your Code Here\n",
    "\n",
    "places_tally = Counter(places)\n",
    "\n",
    "df = pd.DataFrame(places_tally.most_common(), columns=['place', 'count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Type Label|Description|\n",
    "|:---:|:---:|\n",
    "|LANGUAGE|Any named language.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will extract named entitities from *The House on Mango Street*, count them up with `Counter()`, and then create a DataFrame of the results.\n",
    "\n",
    "Your job is to make sure that we only get named entities that are **languages**. Insert the approriate Python code below.\n",
    "\n",
    "*Hint: Look at the examples above for guidance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "languages = []\n",
    "\n",
    "for named_entity in document.ents:\n",
    "    # Your Code Here\n",
    "        # Your Code Here\n",
    "\n",
    "languages_tally = Counter(languages)\n",
    "\n",
    "df = pd.DataFrame(languages_tally.most_common(), columns = ['language', 'count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Another Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Type Label|Description|\n",
    "|:---:|:---:|\n",
    "|PERSON|People, including fictional.|\n",
    "|NORP|Nationalities or religious or political groups.|\n",
    "|FAC|Buildings, airports, highways, bridges, etc.|\n",
    "|ORG|Companies, agencies, institutions, etc.|\n",
    "|GPE|Countries, cities, states.|\n",
    "|LOC|Non-GPE locations, mountain ranges, bodies of water.|\n",
    "|PRODUCT|Objects, vehicles, foods, etc. (Not services.)|\n",
    "|EVENT|Named hurricanes, battles, wars, sports events, etc.|\n",
    "|WORK_OF_ART|Titles of books, songs, etc.|\n",
    "|LAW|Named documents made into laws.|\n",
    "|LANGUAGE|Any named language.|\n",
    "|DATE|Absolute or relative dates or periods.|\n",
    "|TIME|Times smaller than a day.|\n",
    "|PERCENT|Percentage, including ‚Äù%‚Äú.|\n",
    "|MONEY|Monetary values, including unit.|\n",
    "|QUANTITY|Measurements, as of weight or distance.|\n",
    "|ORDINAL|‚Äúfirst‚Äù, ‚Äúsecond‚Äù, etc.|\n",
    "|CARDINAL|Numerals that do not fall under another type.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the examples above, make a DataFrame of a different named entity from the *The House on Mango Street*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# Your Code Here üëá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How well does spaCy's NER seem to be performing?\n",
    "- What does it do well or not so well?\n",
    "- How could you imagine researchers or data scientists using NER?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
