{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4 ‚Äî Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name**: Your name here  \n",
    "**UW ID**: Your ID here  \n",
    "**(Double-click this cell to type)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "In this homework assignment, you will be topic modeling a collection of Reddit posts from the subreddit [r/legaladvice](https://www.reddit.com/r/legaladvice) to understand 15 of its broad themes and trends. All of the posts have an upvote score of 1,000 or more. \n",
    "\n",
    "This homework assignment closely mirror [chapters from our textbook](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/10-Topic-Modeling-CSV.html). You are encouraged to refer back to to the textbook and our class exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: lightblue; padding: 10px\">\n",
    "<p class=\"title\">Note</p>\n",
    "There are sample outputs in the notebook below that demonstrate what your outputs should look like if you use the correct code. You may want to create a copy of this Jupyter notebook so that you can preserve the demonstration outputs and refer to them as you work.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: orange; padding: 10px\">\n",
    "<p class=\"title\">Content Warning</p>\n",
    "I haven't read through all the Reddit posts in the r/legaladvice dataset, but I wanted to warn you that some of the posts are related to sexual harassment and sexual assault. Some of the posts also contain otherwise offensive or inappropriate content. You do not have to engage with these posts if you don't want to. If you would prefer to work with a different dataset, please reach out to me.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lists and List Comprehensions (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you topic model, you will review the two main ways that you can create Python lists.\n",
    "\n",
    "Your task in this section is to make all the Reddit post titles in the list `titles` lowercase and then save them as a new list `lowercase_titles` or `lowercase_titles2`. This workflow will mirror the process that we will use when we prepare Reddit posts for topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['I have been working remotely since march of 2020, I am moving to another state and my employer wants me to resign. State is MA.',\n",
    " 'Can my landlord force me to be exposed to Covid-19? [Dillon, CO]',\n",
    " '(IL) Can I reveal a ‚Äúconfidential‚Äù HR investigation after leaving the company?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make a new list `lowercase_titles` with a `for` loop and the `.append()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_titles = []\n",
    "# Your code hereüëá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then print it out to make sure you have the right answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i have been working remotely since march of 2020, i am moving to another state and my employer wants me to resign. state is ma.', 'can my landlord force me to be exposed to covid-19? [dillon, co]', '(il) can i reveal a ‚Äúconfidential‚Äù hr investigation after leaving the company?']\n"
     ]
    }
   ],
   "source": [
    "print(lowercase_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, make a new list `lowercase_titles2` with a [list comprehension](https://www.w3schools.com/python/python_lists_comprehension.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_titles2 = #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then print it out to make sure you have the right answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i have been working remotely since march of 2020, i am moving to another state and my employer wants me to resign. state is ma.', 'can my landlord force me to be exposed to covid-19? [dillon, co]', '(il) can i reveal a ‚Äúconfidential‚Äù hr investigation after leaving the company?']\n"
     ]
    }
   ],
   "source": [
    "print(lowercase_titles2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the following Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import little_mallet_wrapper\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read in Data (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the CSV file for the [r/legaladvice](https://www.reddit.com/r/legaladvice/) data, which has the following relative filepath ‚Äî \"reddit-data/Legal-Advice-Reddit-Submissions.csv\" ‚Äî and then save it as `reddit_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many Reddit posts are in this DataFrame? Enter your answer in the blank below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ‚Äî you can use any method to find the right answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **____** Reddit posts in this DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many `NaN` values are in the column `\"selftext\"`? Enter your answer in the blank below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ‚Äî you can use any method to find the right answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **____** `NaN` values in the column \"selftext.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert Column to String (1 point)\n",
    "\n",
    "Because there are`NaN` values in the `\"selftext\"` column, we will get errors if we treat them as string data and try to pre-process them. Before we move on, you need to convert the `\"selftext\"` column to the datatype `string` and re-assign it to the same column. Fill in the blank in the code below.\n",
    "\n",
    "*The rest of the notebook will not work if you do not get the correct answer here!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['selftext'] = reddit_df['selftext'].astype(#Your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Reddit Posts and Titles (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the Reddit data for topic modeling, we need to transform all the Reddit posts to lowercase and remove stopwords, punctuation, and numbers.\n",
    "\n",
    "To do so, we will use a `little_mallet_wrapper` function and a list comprehension. Fill in the blank (`YOUR-CODE-HERE`) in the list comprehension below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [little_mallet_wrapper.process_string(YOUR-CODE-HERE, numbers='remove') for text in reddit_df['selftext']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of the original (not pre-processed) Reddit posts and assign it to the variable `original_texts` (completed for you below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts = [text for text in reddit_df['selftext']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of every title from the DataFrame in the column `title` and assign it to the variable `reddit_titles` with a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_titles = [#Your code here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set Up and Train Topic Model (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are setting the number of topics that we want to return, the filepath to Mallet, as well as output filepaths for our topic modeling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 15\n",
    "\n",
    "path_to_mallet = '/home/jovyan/course_materials/mallet/bin/mallet'\n",
    "\n",
    "#No need to change anything below here\n",
    "training_data = training_data\n",
    "\n",
    "#Set output directory\n",
    "output_directory_path = 'topic-model-output/'\n",
    "\n",
    "#Create output directory\n",
    "Path(f\"{output_directory_path}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#Create output files\n",
    "path_to_training_data           = f\"{output_directory_path}/training.txt\"\n",
    "path_to_formatted_training_data = f\"{output_directory_path}/mallet.training\"\n",
    "path_to_model                   = f\"{output_directory_path}/mallet.model.{str(num_topics)}\"\n",
    "path_to_topic_keys              = f\"{output_directory_path}/mallet.topic_keys.{str(num_topics)}\"\n",
    "path_to_topic_distributions     = f\"{output_directory_path}/mallet.topic_distributions.{str(num_topics)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the topic model with `little_mallet_wrapper.quick_train_topic_model()`. Remember that this may take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "little_mallet_wrapper.quick_train_topic_model(path_to_mallet,\n",
    "                                              output_directory_path,\n",
    "                                              num_topics,\n",
    "                                              training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display Topics and Top Words (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the code below to print all the topics with topic number and topic key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "topics = little_mallet_wrapper.load_topic_keys(path_to_topic_keys)\n",
    "\n",
    "# Fill in the blanks below\n",
    "for ___, ____ in enumerate(topics):\n",
    "    print(f\"‚ú®Topic {number}‚ú®\\n\\n{topic}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Topic Distributions (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the topic distributions for all the documents (the probability that each document contains each of the topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions = little_mallet_wrapper.load_topic_distributions(path_to_topic_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Identify and Label 3 Topics (9 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you will choose and closely examine 3 of the 15 topics in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first you need to run the cell below to create the functions that will help you examine the top Reddits posts for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "\n",
    "def make_md(string):\n",
    "    \"\"\"A function that transforms string data into Markdown\n",
    "    so it can be nicely formatted with bolding and emojis\n",
    "    \"\"\"\n",
    "    display(Markdown(str(string)))\n",
    "\n",
    "def get_top_docs(docs, topic_distributions, topic_index, n=5):\n",
    "    \n",
    "    \"\"\"A function that shows the top documents for a given set of topic distributions\n",
    "    and a specific topic number\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_data = sorted([(_distribution[topic_index], _document) for _distribution, _document in zip(topic_distributions, docs)], reverse=True)\n",
    "    topic_words = topics[topic_index]\n",
    "    make_md(f\"### ‚ú®Topic {topic_index}‚ú®\\n\\n{topic_words}\\n\\n---\")\n",
    "    \n",
    "    for probability, doc in sorted_data[:n]:\n",
    "        # Make topic words bolded\n",
    "        for word in topic_words:\n",
    "            if word in doc.lower():\n",
    "                doc = re.sub(f\"\\\\b{word}\\\\b\", f\"**{word}**\", doc, re.IGNORECASE)\n",
    "        make_md(f'‚ú®  \\n**Topic Probability**: {probability}  \\n**Document**: {doc}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the top 5 Reddit **titles** with the highest probability of containing your topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ‚Äî¬†use the get_top_docs() function from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the top 5 Reddit **posts** with the highest probability of containing your topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ‚Äî¬†use the get_top_docs() function from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the topic words and the top documents, come up with a label for your first topic and fill in the details below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic *Number Here***: First Five Topic Words Here  \n",
    "**Topic Label**: Topic Label Here  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the top 5 Reddit **titles** with the highest probability of containing your topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ‚Äî¬†use the get_top_docs() function from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the top 5 Reddit **posts** with the highest probability of containing your topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ‚Äî¬†use the get_top_docs() function from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the topic words and the top documents, come up with a label for your second topic and fill in the details below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic *Number Here***: First Five Topic Words Here  \n",
    "**Topic Label**: Topic Label Here  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the top 5 Reddit **titles** with the highest probability of containing your topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ‚Äî¬†use the get_top_docs() function from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the top 5 Reddit **posts** with the highest probability of containing your topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ‚Äî¬†use the get_top_docs() function from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the topic words and the top documents, come up with a label for your third topic and fill in the details below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic *Number Here***: First Five Topic Words Here  \n",
    "**Topic Label**: Topic Label Here  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9/10. Reflection (2 points each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2-5 sentences, answer the following questions:\n",
    "- What kind of further research or analysis could you do with your 3 chosen topics or with any of the other topics? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What do you think is the most difficult topic to label of all 15 topics? Why? If you had to label it (even with a wild guess), what would you label it? Be sure to include the top 5 words from this topic in your response "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When You're Finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're finished, you should:\n",
    "\n",
    "1. Save your Jupyter notebook with your last name. To save your notebook, you can select File -> Save Notebook or File -> Save Notebook As...\n",
    "\n",
    "2. Download your Jupyter notebook file (.ipynb), and then upload it to [Gradescope](https://www.gradescope.com/courses/322397/assignments/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
