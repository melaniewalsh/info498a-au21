{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2 — Build Your Own Word Frequency Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name**: Your name here  \n",
    "**UW ID**: Your ID here  \n",
    "**(Double-click this cell to type)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: lightblue; padding: 10px\">\n",
    "<p class=\"title\">Note</p>\n",
    "There are many sample outputs in the notebook below that demonstrate what your outputs should look like if you are defining functions correctly and using the correct code. You may want to create a copy of this Jupyter notebook so that you can preserve the demonstration outputs and refer to them as you work.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework assignment, you will be building your own word frequency counter Python script: `my_word_counter.py`. Your word counter Python script must split any text into individual words, make the words lowercase, remove stopwords, count words by frequency, and then return the top 15 most frequent words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End goal**\n",
    "\n",
    "*Note: The cell below will not work until you have completed the entire assignment! It is here for demonstration purposes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('darden', 14), ('dr', 11), ('said', 9), ('nasa', 8), ('women', 8), ('engineering', 7), ('school', 6), ('time', 6), ('one', 5), ('hidden', 5), ('figures', 5), ('gw', 5), ('screening', 5), ('film', 5), ('movie', 5)]\n"
     ]
    }
   ],
   "source": [
    "!python my_word_counter.py GW-Hidden-Figures-Article.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will test your word counter Python script on one of 3 text files: F. Scott Fitzgerald's novel *The Great Gatsby* (1925) (`The-Great-Gatsby_Fitzgerald.txt`); Donald Trump's tweets from 2016 to early 2020 (`Trump-Tweets_2016-2020.txt`); or Scottish cartographer J.G. Bartholomew's *A Literary and Historical Atlas of Asia* (1900) (`Atlas-of-Asia.txt`). You can find more details about these texts as well as helpful background on some of the Python packages necessary for this assignment in `Ω-Appendix.ipynb`.\n",
    "\n",
    "Though the above Python script is our end goal, we are going to start small and build our way up to it by writing smaller bits of code.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages, Modules, and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything else, let's import the two Python modules that we will need for this assignment. We will use `re`, the regular expressions library, to more effectively tokenize words, and we will use `Counter` to count the number of words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make a Function That Will Lowercase and Split Words (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a function that accepts a string/text, makes the text lowercase and splits the text into individual words, and finally returns a list of lowercased words. (Make sure you use `return` and not `print()`!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower_and_split(text):\n",
    "    \"\"\"Make a function that accepts a string/text, makes the text lowercase and\n",
    "    splits it into indivdual words, then finally returns a list of lowercased words\"\"\"\n",
    "    #Your code here\n",
    "    split_text = re.split('\\W+', lowered_text)\n",
    "    #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out your function `make_lower_and_split()` to see if it works on the `test_text` below. You should be able to simply run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gatsby', 'believed', 'in', 'the', 'green', 'light', 'the', 'orgastic', 'future', 'that', 'year', 'by', 'year', 'recedes', 'before', 'us', 'it', 'eluded', 'us', 'then', 'but', 'that', 's', 'no', 'matter', 'tomorrow', 'we', 'will', 'run', 'faster', 'stretch', 'out', 'our', 'arms', 'further', 'and', 'one', 'fine', 'morning', 'so', 'we', 'beat', 'on', 'boats', 'against', 'the', 'current', 'borne', 'back', 'ceaselessly', 'into', 'the', 'past', '']\n"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\"Gatsby believed in the green light, the orgastic future that year by\n",
    "                year recedes before us. It eluded us then, but that’s no\n",
    "                matter—tomorrow we will run faster, stretch out our arms further... And\n",
    "                one fine morning—\n",
    "\n",
    "                So we beat on, boats against the current, borne back ceaselessly into\n",
    "                the past.\"\"\"\n",
    "\n",
    "tokenized_text = make_lower_and_split(test_text)\n",
    "\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check that you are returning a list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make a Function That Will Remove Stopwords (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create your own list of stopwords and then assign it to the variable `stopwords` below. You can copy and paste the stopwords used in previous notebooks, or you can create/alter your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = # Create your own list of stopwords here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, define a function that accepts a list of words and returns a new list of words with stopwords ignored/removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    \"\"\"Make a function that accepts a list of words,\n",
    "    then returns a new list of words with stopwords ignored/removed\"\"\"\n",
    "    \n",
    "    meaningful_words = []\n",
    "    #Your code here👇\n",
    "    \n",
    "    \n",
    "    \n",
    "    return meaningful_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out your function `remove_stopwords()` to see if it works on the `tokenized_text` below. You should be able to simply run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gatsby',\n",
       " 'believed',\n",
       " 'green',\n",
       " 'light',\n",
       " 'orgastic',\n",
       " 'future',\n",
       " 'year',\n",
       " 'year',\n",
       " 'recedes',\n",
       " 'us',\n",
       " 'eluded',\n",
       " 'us',\n",
       " 'matter',\n",
       " 'tomorrow',\n",
       " 'run',\n",
       " 'faster',\n",
       " 'stretch',\n",
       " 'arms',\n",
       " 'one',\n",
       " 'fine',\n",
       " 'morning',\n",
       " 'beat',\n",
       " 'boats',\n",
       " 'current',\n",
       " 'borne',\n",
       " 'back',\n",
       " 'ceaselessly',\n",
       " 'past',\n",
       " '']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"\"\"Gatsby believed in the green light, the orgastic future that year by\n",
    "                year recedes before us. It eluded us then, but that’s no\n",
    "                matter—tomorrow we will run faster, stretch out our arms further... And\n",
    "                one fine morning—\n",
    "\n",
    "                So we beat on, boats against the current, borne back ceaselessly into\n",
    "                the past.\"\"\"\n",
    "\n",
    "tokenized_text = make_lower_and_split(test_text)\n",
    "\n",
    "remove_stopwords(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make a Function That Will Return The Most Common 15 Words From a List (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a function that accepts a list of words, calculates the frequency of the words, and then returns the 15 most frequent words. Hint: use the `Counter()` function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common(words, number_of_words=15):\n",
    "    \"\"\"Make a function that accepts a list of words, calculates the frequency of the words,\n",
    "    then returns the 15 most frequent words\"\"\"\n",
    "    #Your code here 👇\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out your function `get_most_common()` to see if it works on the `meaningful_words` below. You should be able to simply run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year', 2),\n",
       " ('us', 2),\n",
       " ('gatsby', 1),\n",
       " ('believed', 1),\n",
       " ('green', 1),\n",
       " ('light', 1),\n",
       " ('orgastic', 1),\n",
       " ('future', 1),\n",
       " ('recedes', 1),\n",
       " ('eluded', 1),\n",
       " ('matter', 1),\n",
       " ('tomorrow', 1),\n",
       " ('run', 1),\n",
       " ('faster', 1),\n",
       " ('stretch', 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"\"\"Gatsby believed in the green light, the orgastic future that year by\n",
    "                year recedes before us. It eluded us then, but that’s no\n",
    "                matter—tomorrow we will run faster, stretch out our arms further... And\n",
    "                one fine morning—\n",
    "\n",
    "                So we beat on, boats against the current, borne back ceaselessly into\n",
    "                the past.\"\"\"\n",
    "\n",
    "tokenized_text = make_lower_and_split(test_text)\n",
    "meaningful_words = remove_stopwords(tokenized_text)\n",
    "\n",
    "get_most_common(meaningful_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Read in a File (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the text file of your choice and print the first 500 characters.\n",
    "\n",
    "You can choose F. Scott Fitzgerald's novel *The Great Gatsby* (1925) (`The-Great-Gatsby_Fitzgerald.txt`); Donald Trump's tweets from 2016 to early 2020 (`Trump-Tweets_2016-2020.txt`); or Scottish cartographer J.G. Bartholomew's *A Literary and Historical Atlas of Asia* (1900) (`Atlas-of-Asia.txt`. (Make sure you specify the `mode` and `encoding` when reading the file!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christine Darden Is One of NASA’s ‘Hidden Figures’\n",
      "The GW alumna talked about her work at the space agency and her career in mathematics and engineering after a screening of the award-winning film.\n",
      "\n",
      "February 22, 2018\n",
      "By B.L. Wilson\n",
      "\n",
      "NASA engineer Christine Darden is often asked which movie star played her in the motion picture “Hidden Figures,” the film about African American women who worked as human computers during the era of the space race.\n",
      "\n",
      "“I am not in the movie, but I am in the book,” she\n"
     ]
    }
   ],
   "source": [
    "text = #Your code here\n",
    "\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Put It All Together (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, combine all the functions and code that you've written so far so that we can run this one cell below and print out the 15 most frequent words from the text file of your choice.\n",
    "\n",
    "Copy and paste your functions from above into the appropriate places below; make sure you assign the variables `stopwords` and `filepath_of_text`; and finally include code to read in the text file. Then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('darden', 14), ('dr', 11), ('said', 9), ('nasa', 8), ('women', 8), ('engineering', 7), ('school', 6), ('time', 6), ('one', 5), ('hidden', 5), ('figures', 5), ('gw', 5), ('screening', 5), ('film', 5), ('movie', 5)]\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries and Modules\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import sys\n",
    "\n",
    "# Define Functions\n",
    "\n",
    "\"\"\"Copy and paste the code you used to define the functions above\"\"\"\n",
    "\n",
    "def make_lower_and_split(text):\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \n",
    "def get_most_common(words, number_of_words=15):\n",
    "\n",
    "# Define Filepaths and Assign Variables\n",
    "\n",
    "stopwords = \"\"\"Your code here\"\"\"\n",
    "\n",
    "filepath_of_text =  \"\"\"Your code here\"\"\"\n",
    "\n",
    "# Read in File\n",
    "\n",
    "text = \"\"\"Your code here\"\"\"\n",
    "\n",
    "# Manipulate and Analyze File\n",
    "\n",
    "tokenized_text = make_lower_and_split(text)\n",
    "meaningful_words = remove_stopwords(tokenized_text)\n",
    "most_frequent_meaningful_words = get_most_common(meaningful_words)\n",
    "\n",
    "# Output Results\n",
    "\n",
    "print(most_frequent_meaningful_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make Your Own Python Script and Run it From the Command Line (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our final step, take the code above and make it into its own stand-alone Python script `my_word_counter.py`, which will be able to accept *any* text file and return the 15 most frequent words.\n",
    "\n",
    "Double click the file `my_word_counter.py` from the file browser on the left-hand side of your JupyterHub and fill in Python code in the appropriate places. Then run the cell below with the text file name of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('darden', 14), ('dr', 11), ('said', 9), ('nasa', 8), ('women', 8), ('engineering', 7), ('school', 6), ('time', 6), ('one', 5), ('hidden', 5), ('figures', 5), ('gw', 5), ('screening', 5), ('film', 5), ('movie', 5)]\n"
     ]
    }
   ],
   "source": [
    "!python my_word_counter.py #your filename here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Synthesize (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a few sentences, answer the following questions:\n",
    "- What do you think you can learn about your text based on the most frequent words, if anything?\n",
    "- What do you think is getting left out by focusing on the most frequent words, if anything?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Double-click this cell to type)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Stopwords (2 extra credit points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your results above, add or remove at least 5 stopwords from your stopwords list, and then run your script again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python my_word_counter.py #filename here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What stopwords did you choose to add/remove, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Double-click this cell to type)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When You're Finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're finished, you should:\n",
    "\n",
    "1. Save your Jupyter notebook with your last name. To save your notebook, you can select File -> Save Notebook or File -> Save Notebook As...\n",
    "\n",
    "2. Download your Jupyter notebook file (.ipynb), and then upload it to [Gradescope](https://www.gradescope.com/courses/322397/assignments/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
